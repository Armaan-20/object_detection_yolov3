{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNso+bLMLTYKJLn9s8Aj7j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Armaan-20/object_detection_yolov3/blob/main/Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOBG6F5o0vwJ"
      },
      "source": [
        "!git clone https://github.com/AlexeyAB/darknet\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYhDkOq02J3y"
      },
      "source": [
        "%cd darknet\r\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\r\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\r\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XULbOYGO2RGA"
      },
      "source": [
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S03s9RTm3poE"
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-erZYgY78QPt"
      },
      "source": [
        "!wget https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQTUwed76KaF"
      },
      "source": [
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import urllib.request\r\n",
        "\r\n",
        "weight = '/content/darknet/yolov3.weights.1'\r\n",
        "cfg = '/content/darknet/cfg/yolov3.cfg'\r\n",
        "\r\n",
        "net = cv2.dnn.readNet(weight, cfg)\r\n",
        "\r\n",
        "classes = []\r\n",
        "with open(\"/content/darknet/data/coco.names\", \"r\") as f:\r\n",
        "    classes = f.read().splitlines()\r\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6SA-SgKVkez"
      },
      "source": [
        "# import dependencies\r\n",
        "from IPython.display import display, Javascript, Image\r\n",
        "from google.colab.output import eval_js\r\n",
        "from base64 import b64decode, b64encode\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import PIL\r\n",
        "import io\r\n",
        "import html\r\n",
        "import time\r\n",
        "# function to convert the JavaScript object into an OpenCV image\r\n",
        "def js_to_image(js_reply):\r\n",
        "  \"\"\"\r\n",
        "  Params:\r\n",
        "          js_reply: JavaScript object containing image from webcam\r\n",
        "  Returns:\r\n",
        "          img: OpenCV BGR image\r\n",
        "  \"\"\"\r\n",
        "  # decode base64 image\r\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\r\n",
        "  # convert bytes to numpy array\r\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\r\n",
        "  # decode numpy array into OpenCV BGR image\r\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\r\n",
        "\r\n",
        "  return img\r\n",
        "# JavaScript to properly create our live video stream using our webcam as input\r\n",
        "def video_stream():\r\n",
        "  js = Javascript('''\r\n",
        "    var video;\r\n",
        "    var div = null;\r\n",
        "    var stream;\r\n",
        "    var captureCanvas;\r\n",
        "    var imgElement;\r\n",
        "    var labelElement;\r\n",
        "    \r\n",
        "    var pendingResolve = null;\r\n",
        "    var shutdown = false;\r\n",
        "    \r\n",
        "    function removeDom() {\r\n",
        "       stream.getVideoTracks()[0].stop();\r\n",
        "       video.remove();\r\n",
        "       div.remove();\r\n",
        "       video = null;\r\n",
        "       div = null;\r\n",
        "       stream = null;\r\n",
        "       imgElement = null;\r\n",
        "       captureCanvas = null;\r\n",
        "       labelElement = null;\r\n",
        "    }\r\n",
        "    \r\n",
        "    function onAnimationFrame() {\r\n",
        "      if (!shutdown) {\r\n",
        "        window.requestAnimationFrame(onAnimationFrame);\r\n",
        "      }\r\n",
        "      if (pendingResolve) {\r\n",
        "        var result = \"\";\r\n",
        "        if (!shutdown) {\r\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\r\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\r\n",
        "        }\r\n",
        "        var lp = pendingResolve;\r\n",
        "        pendingResolve = null;\r\n",
        "        lp(result);\r\n",
        "      }\r\n",
        "    }\r\n",
        "    \r\n",
        "    async function createDom() {\r\n",
        "      if (div !== null) {\r\n",
        "        return stream;\r\n",
        "      }\r\n",
        "\r\n",
        "      div = document.createElement('div');\r\n",
        "      div.style.border = '2px solid black';\r\n",
        "      div.style.padding = '3px';\r\n",
        "      div.style.width = '100%';\r\n",
        "      div.style.maxWidth = '600px';\r\n",
        "      document.body.appendChild(div);\r\n",
        "      \r\n",
        "      const modelOut = document.createElement('div');\r\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\r\n",
        "      labelElement = document.createElement('span');\r\n",
        "      labelElement.innerText = 'No data';\r\n",
        "      labelElement.style.fontWeight = 'bold';\r\n",
        "      modelOut.appendChild(labelElement);\r\n",
        "      div.appendChild(modelOut);\r\n",
        "           \r\n",
        "      video = document.createElement('video');\r\n",
        "      video.style.display = 'block';\r\n",
        "      video.width = div.clientWidth - 6;\r\n",
        "      video.setAttribute('playsinline', '');\r\n",
        "      video.onclick = () => { shutdown = true; };\r\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\r\n",
        "          {video: { facingMode: \"environment\"}});\r\n",
        "      div.appendChild(video);\r\n",
        "\r\n",
        "      imgElement = document.createElement('img');\r\n",
        "      imgElement.style.position = 'absolute';\r\n",
        "      imgElement.style.zIndex = 1;\r\n",
        "      imgElement.onclick = () => { shutdown = true; };\r\n",
        "      div.appendChild(imgElement);\r\n",
        "      \r\n",
        "      const instruction = document.createElement('div');\r\n",
        "      instruction.innerHTML = \r\n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\r\n",
        "          'When finished, click here or on the video to stop this demo</span>';\r\n",
        "      div.appendChild(instruction);\r\n",
        "      instruction.onclick = () => { shutdown = true; };\r\n",
        "      \r\n",
        "      video.srcObject = stream;\r\n",
        "      await video.play();\r\n",
        "\r\n",
        "      captureCanvas = document.createElement('canvas');\r\n",
        "      captureCanvas.width = 640; //video.videoWidth;\r\n",
        "      captureCanvas.height = 480; //video.videoHeight;\r\n",
        "      window.requestAnimationFrame(onAnimationFrame);\r\n",
        "      \r\n",
        "      return stream;\r\n",
        "    }\r\n",
        "    async function stream_frame(label, imgData) {\r\n",
        "      if (shutdown) {\r\n",
        "        removeDom();\r\n",
        "        shutdown = false;\r\n",
        "        return '';\r\n",
        "      }\r\n",
        "\r\n",
        "      var preCreate = Date.now();\r\n",
        "      stream = await createDom();\r\n",
        "      \r\n",
        "      var preShow = Date.now();\r\n",
        "      if (label != \"\") {\r\n",
        "        labelElement.innerHTML = label;\r\n",
        "      }\r\n",
        "            \r\n",
        "      if (imgData != \"\") {\r\n",
        "        var videoRect = video.getClientRects()[0];\r\n",
        "        imgElement.style.top = videoRect.top + \"px\";\r\n",
        "        imgElement.style.left = videoRect.left + \"px\";\r\n",
        "        imgElement.style.width = videoRect.width + \"px\";\r\n",
        "        imgElement.style.height = videoRect.height + \"px\";\r\n",
        "        imgElement.src = imgData;\r\n",
        "      }\r\n",
        "      \r\n",
        "      var preCapture = Date.now();\r\n",
        "      var result = await new Promise(function(resolve, reject) {\r\n",
        "        pendingResolve = resolve;\r\n",
        "      });\r\n",
        "      shutdown = false;\r\n",
        "      \r\n",
        "      return {'create': preShow - preCreate, \r\n",
        "              'show': preCapture - preShow, \r\n",
        "              'capture': Date.now() - preCapture,\r\n",
        "              'img': result};\r\n",
        "    }\r\n",
        "    ''')\r\n",
        "\r\n",
        "  display(js)\r\n",
        "  \r\n",
        "def video_frame(label, bbox):\r\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\r\n",
        "  return data\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odDUfts_1t-h"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\r\n",
        "font = cv2.FONT_HERSHEY_PLAIN\r\n",
        "colors = np.random.uniform(0, 255, size=(100, 3))\r\n",
        "cap = cv2.VideoCapture('/content/Times_Square_Sidewalk.mp4')\r\n",
        "while True:\r\n",
        "  _, img = cap.read()\r\n",
        "  height, width, _ = img.shape\r\n",
        "\r\n",
        "  blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\r\n",
        "  net.setInput(blob)\r\n",
        "  output_layers_names = net.getUnconnectedOutLayersNames()\r\n",
        "  layerOutputs = net.forward(output_layers_names)\r\n",
        "\r\n",
        "  boxes = []\r\n",
        "  confidences = []\r\n",
        "  class_ids = []\r\n",
        "\r\n",
        "  for output in layerOutputs:\r\n",
        "      for detection in output:\r\n",
        "          scores = detection[5:]\r\n",
        "          class_id = np.argmax(scores)\r\n",
        "          confidence = scores[class_id]\r\n",
        "          if confidence > 0.2:\r\n",
        "              center_x = int(detection[0]*width)\r\n",
        "              center_y = int(detection[1]*height)\r\n",
        "              w = int(detection[2]*width)\r\n",
        "              h = int(detection[3]*height)\r\n",
        "\r\n",
        "              x = int(center_x - w/2)\r\n",
        "              y = int(center_y - h/2)\r\n",
        "\r\n",
        "              boxes.append([x, y, w, h])\r\n",
        "              confidences.append((float(confidence)))\r\n",
        "              class_ids.append(class_id)\r\n",
        "\r\n",
        "  indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.2, 0.4)\r\n",
        "\r\n",
        "\r\n",
        "  if len(indexes)>0:\r\n",
        "      for i in indexes.flatten():\r\n",
        "          x, y, w, h = boxes[i]\r\n",
        "          label = str(classes[class_ids[i]])\r\n",
        "          confidence = str(round(confidences[i],2))\r\n",
        "          color = colors[i]\r\n",
        "          cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\r\n",
        "          cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255,255,255), 2)\r\n",
        "\r\n",
        "  cv2_imshow(img)\r\n",
        "  key = cv2.waitKey(1)\r\n",
        "  if key == 2:\r\n",
        "    break\r\n",
        "cap.release()\r\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}